{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gopal2812/mlblr/blob/master/seconditerationdensenetcifar10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "a0sOlwsKOm9O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfqibnbjOpYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7352
        },
        "outputId": "74187a68-52a8-4814-9e9d-592fced0297d"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 24\n",
        "num_filter = 64\n",
        "compression = 0.5\n",
        "dropout_rate = 0.5\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "  \n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg\n",
        "  \n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output\n",
        "  \n",
        "num_filter = 64\n",
        "dropout_rate = 0.2\n",
        "l = 6\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n",
        "\n",
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 16s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   1728        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           conv2d_1[0][0]                   \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 96)   384         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 96)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   27648       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   36864       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 32)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 160)  0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   46080       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 192)  0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 192)  768         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   55296       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 224)  0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 224)  896         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 224)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   64512       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 32)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 256)  0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 32)   8192        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 32)   0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   9216        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 64)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   18432       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 96)   0           concatenate_7[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   384         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   27648       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 16, 16, 32)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 128)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   36864       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 16, 16, 32)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 160)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 160)  640         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 160)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   46080       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 16, 16, 32)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 192)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 192)  768         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 192)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 32)   55296       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 16, 16, 32)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 16, 16, 224)  0           concatenate_11[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 224)  896         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 224)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 32)   7168        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 16, 16, 32)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 32)     0           dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 32)     128         average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 32)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 32)     9216        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 8, 8, 32)     0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 64)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 32)     18432       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 8, 8, 32)     0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 96)     0           concatenate_13[0][0]             \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 96)     384         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 96)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 32)     27648       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 8, 8, 32)     0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 8, 8, 128)    0           concatenate_14[0][0]             \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 32)     36864       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 8, 8, 32)     0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 8, 8, 160)    0           concatenate_15[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 160)    640         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 160)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 32)     46080       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 8, 8, 32)     0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 8, 8, 192)    0           concatenate_16[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 192)    768         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 192)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 32)     55296       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 8, 8, 32)     0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 8, 8, 224)    0           concatenate_17[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 224)    896         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 224)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 32)     7168        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 8, 8, 32)     0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 32)     0           dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4, 4, 32)     128         average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 32)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 32)     9216        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 4, 4, 32)     0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 4, 4, 64)     0           average_pooling2d_3[0][0]        \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 64)     256         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 64)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 32)     18432       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 4, 4, 32)     0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 4, 4, 96)     0           concatenate_19[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 96)     384         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 96)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 32)     27648       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 4, 4, 32)     0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 4, 4, 128)    0           concatenate_20[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 128)    512         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 128)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 32)     36864       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 4, 4, 32)     0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 4, 4, 160)    0           concatenate_21[0][0]             \n",
            "                                                                 dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 160)    640         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 160)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 32)     46080       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 4, 4, 32)     0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 4, 4, 192)    0           concatenate_22[0][0]             \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 192)    768         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 192)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 32)     55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 4, 4, 32)     0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 4, 4, 224)    0           concatenate_23[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 224)    896         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 224)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 224)    0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 896)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           8970        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 877,898\n",
            "Trainable params: 870,282\n",
            "Non-trainable params: 7,616\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 197s 4ms/step - loss: 1.3764 - acc: 0.4988 - val_loss: 2.1251 - val_acc: 0.4105\n",
            "Epoch 2/50\n",
            "19200/50000 [==========>...................] - ETA: 1:47 - loss: 0.9890 - acc: 0.6460"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.9310 - acc: 0.6676 - val_loss: 1.3788 - val_acc: 0.5932\n",
            "Epoch 3/50\n",
            "45568/50000 [==========================>...] - ETA: 15s - loss: 0.7491 - acc: 0.7337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.7476 - acc: 0.7342 - val_loss: 0.8431 - val_acc: 0.7152\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.6526 - acc: 0.7695 - val_loss: 1.4238 - val_acc: 0.5866\n",
            "Epoch 5/50\n",
            " 3328/50000 [>.............................] - ETA: 2:42 - loss: 0.6331 - acc: 0.7755"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.5820 - acc: 0.7953 - val_loss: 0.7632 - val_acc: 0.7582\n",
            "Epoch 6/50\n",
            "39552/50000 [======================>.......] - ETA: 36s - loss: 0.5312 - acc: 0.8167"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.5285 - acc: 0.8172 - val_loss: 0.6029 - val_acc: 0.7993\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.4867 - acc: 0.8284 - val_loss: 0.6539 - val_acc: 0.7869\n",
            "Epoch 8/50\n",
            " 1920/50000 [>.............................] - ETA: 2:48 - loss: 0.4289 - acc: 0.8479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.4513 - acc: 0.8407 - val_loss: 0.7744 - val_acc: 0.7602\n",
            "Epoch 9/50\n",
            "38912/50000 [======================>.......] - ETA: 38s - loss: 0.4142 - acc: 0.8543"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.4164 - acc: 0.8543 - val_loss: 0.8146 - val_acc: 0.7583\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.3958 - acc: 0.8604 - val_loss: 0.7928 - val_acc: 0.7522\n",
            "Epoch 11/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.3748 - acc: 0.8626"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.3693 - acc: 0.8713 - val_loss: 1.6611 - val_acc: 0.6107\n",
            "Epoch 12/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.3495 - acc: 0.8776"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.3526 - acc: 0.8762 - val_loss: 0.7093 - val_acc: 0.7850\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.3263 - acc: 0.8849 - val_loss: 0.6951 - val_acc: 0.8013\n",
            "Epoch 14/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.2874 - acc: 0.9049"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.3122 - acc: 0.8901 - val_loss: 0.7807 - val_acc: 0.7944\n",
            "Epoch 15/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.3010 - acc: 0.8945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.3007 - acc: 0.8939 - val_loss: 0.6380 - val_acc: 0.8026\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.2768 - acc: 0.9030 - val_loss: 0.5835 - val_acc: 0.8310\n",
            "Epoch 17/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.2660 - acc: 0.9069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.2660 - acc: 0.9049 - val_loss: 0.7299 - val_acc: 0.7985\n",
            "Epoch 18/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.2557 - acc: 0.9099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.2553 - acc: 0.9097 - val_loss: 0.8300 - val_acc: 0.7874\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.2432 - acc: 0.9152 - val_loss: 0.6781 - val_acc: 0.8184\n",
            "Epoch 20/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.2333 - acc: 0.9212"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.2328 - acc: 0.9153 - val_loss: 0.6348 - val_acc: 0.8265\n",
            "Epoch 21/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.2170 - acc: 0.9237"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 188s 4ms/step - loss: 0.2181 - acc: 0.9234 - val_loss: 0.8605 - val_acc: 0.7768\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.2151 - acc: 0.9238 - val_loss: 0.5472 - val_acc: 0.8446\n",
            "Epoch 23/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.2058 - acc: 0.9212"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.2033 - acc: 0.9270 - val_loss: 0.5425 - val_acc: 0.8515\n",
            "Epoch 24/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1868 - acc: 0.9339"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1918 - acc: 0.9315 - val_loss: 0.5727 - val_acc: 0.8518\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1857 - acc: 0.9327 - val_loss: 0.7493 - val_acc: 0.8171\n",
            "Epoch 26/50\n",
            " 1536/50000 [..............................] - ETA: 2:48 - loss: 0.1860 - acc: 0.9355"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1827 - acc: 0.9343 - val_loss: 0.5733 - val_acc: 0.8572\n",
            "Epoch 27/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1654 - acc: 0.9414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1704 - acc: 0.9391 - val_loss: 0.6194 - val_acc: 0.8423\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1676 - acc: 0.9397 - val_loss: 0.7471 - val_acc: 0.8263\n",
            "Epoch 29/50\n",
            " 1536/50000 [..............................] - ETA: 2:48 - loss: 0.1621 - acc: 0.9368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1595 - acc: 0.9434 - val_loss: 0.6125 - val_acc: 0.8485\n",
            "Epoch 30/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1501 - acc: 0.9448"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1533 - acc: 0.9440 - val_loss: 0.5595 - val_acc: 0.8616\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 187s 4ms/step - loss: 0.1486 - acc: 0.9462 - val_loss: 0.6261 - val_acc: 0.8543\n",
            "Epoch 32/50\n",
            " 1536/50000 [..............................] - ETA: 2:48 - loss: 0.1357 - acc: 0.9531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1410 - acc: 0.9503 - val_loss: 0.6718 - val_acc: 0.8324\n",
            "Epoch 33/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1349 - acc: 0.9507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1386 - acc: 0.9496 - val_loss: 0.6267 - val_acc: 0.8466\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1332 - acc: 0.9518 - val_loss: 0.6352 - val_acc: 0.8544\n",
            "Epoch 35/50\n",
            " 1536/50000 [..............................] - ETA: 2:47 - loss: 0.1127 - acc: 0.9622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1322 - acc: 0.9518 - val_loss: 0.5489 - val_acc: 0.8666\n",
            "Epoch 36/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1175 - acc: 0.9581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1205 - acc: 0.9568 - val_loss: 0.5905 - val_acc: 0.8611\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1194 - acc: 0.9573 - val_loss: 0.8284 - val_acc: 0.8210\n",
            "Epoch 38/50\n",
            " 1536/50000 [..............................] - ETA: 2:48 - loss: 0.1297 - acc: 0.9551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1247 - acc: 0.9555 - val_loss: 0.6501 - val_acc: 0.8568\n",
            "Epoch 39/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1145 - acc: 0.9595"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1160 - acc: 0.9589 - val_loss: 0.6666 - val_acc: 0.8445\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1088 - acc: 0.9593 - val_loss: 0.6087 - val_acc: 0.8646\n",
            "Epoch 41/50\n",
            " 1536/50000 [..............................] - ETA: 2:48 - loss: 0.0903 - acc: 0.9681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1088 - acc: 0.9610 - val_loss: 0.6229 - val_acc: 0.8604\n",
            "Epoch 42/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.1023 - acc: 0.9629"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1047 - acc: 0.9619 - val_loss: 0.6203 - val_acc: 0.8633\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1010 - acc: 0.9626 - val_loss: 0.8060 - val_acc: 0.8310\n",
            "Epoch 44/50\n",
            " 1536/50000 [..............................] - ETA: 2:49 - loss: 0.0886 - acc: 0.9635"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.1008 - acc: 0.9641 - val_loss: 0.6647 - val_acc: 0.8570\n",
            "Epoch 45/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.0983 - acc: 0.9648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0989 - acc: 0.9645 - val_loss: 0.7396 - val_acc: 0.8465\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0991 - acc: 0.9646 - val_loss: 0.6375 - val_acc: 0.8613\n",
            "Epoch 47/50\n",
            " 1536/50000 [..............................] - ETA: 2:47 - loss: 0.0906 - acc: 0.9681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0909 - acc: 0.9672 - val_loss: 0.5755 - val_acc: 0.8756\n",
            "Epoch 48/50\n",
            "38656/50000 [======================>.......] - ETA: 39s - loss: 0.0892 - acc: 0.9680"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0940 - acc: 0.9661 - val_loss: 0.6726 - val_acc: 0.8561\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0882 - acc: 0.9690 - val_loss: 0.6432 - val_acc: 0.8692\n",
            "Epoch 50/50\n",
            " 1536/50000 [..............................] - ETA: 2:47 - loss: 0.0758 - acc: 0.9707"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 186s 4ms/step - loss: 0.0858 - acc: 0.9686 - val_loss: 0.5965 - val_acc: 0.8735\n",
            "10000/10000 [==============================] - 17s 2ms/step\n",
            "Test loss: 0.5964930905386806\n",
            "Test accuracy: 0.8735\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
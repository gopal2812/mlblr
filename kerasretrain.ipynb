{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled29.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopal2812/mlblr/blob/master/kerasretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgev1TJh5Bdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "\n",
        "img_width, img_height = 256, 256\n",
        "train_data_dir = \"tf_files/codoon_photos\"\n",
        "validation_data_dir = \"tf_files/codoon_photos\"\n",
        "nb_train_samples = 4125\n",
        "nb_validation_samples = 466 \n",
        "batch_size = 16\n",
        "epochs = 50\n",
        "\n",
        "model = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
        "\n",
        "\n",
        "\n",
        "# Freeze the layers which you don't want to train. Here I am freezing the all layers.\n",
        "for layer in model.layers[:]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding custom Layer\n",
        "# We only add\n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "# Adding even more custom layers\n",
        "# x = Dense(1024, activation=\"relu\")(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "# x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "# Initiate the train and test generators with data Augumentation \n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  horizontal_flip = True,\n",
        "  fill_mode = \"nearest\",\n",
        "  zoom_range = 0.3,\n",
        "  width_shift_range = 0.3,\n",
        "  height_shift_range=0.3,\n",
        "  rotation_range=30)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  horizontal_flip = True,\n",
        "  fill_mode = \"nearest\",\n",
        "  zoom_range = 0.3,\n",
        "  width_shift_range = 0.3,\n",
        "  height_shift_range=0.3,\n",
        "  rotation_range=30)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size = (img_height, img_width),\n",
        "  batch_size = batch_size,\n",
        "  class_mode = \"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "  validation_data_dir,\n",
        "  target_size = (img_height, img_width),\n",
        "  class_mode = \"categorical\")\n",
        "\n",
        "# Save the model according to the conditions  \n",
        "checkpoint = ModelCheckpoint(\"resnet50_retrain.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "# Train the model \n",
        "model_final.fit_generator(\n",
        "  train_generator,\n",
        "  samples_per_epoch = nb_train_samples,\n",
        "  epochs = epochs,\n",
        "  validation_data = validation_generator,\n",
        "  nb_val_samples = nb_validation_samples,\n",
        "  callbacks = [checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}